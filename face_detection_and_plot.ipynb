{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd13fff0",
   "metadata": {},
   "source": [
    "***1. Make Some Detections***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15f1161",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mediapipe as mp # Import mediapipe\n",
    "import cv2 # Import opencv\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score # Accuracy metrics \n",
    "import pickle \n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "%matplotlib \n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_holistic = mp.solutions.holistic # Mediapipe Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89251c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIVE\n",
    "#cap = cv2.VideoCapture(0)\n",
    "#happy/neutral/peaceful/suiron\n",
    "filepath_input = \"./emotions/happy.mp4\"\n",
    "filepath_output = \"./result/happy.mp4\"\n",
    "cap = cv2.VideoCapture(filepath_input)\n",
    "#video save\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) # 動画の画面横幅\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) # 動画の画面縦幅\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) # 総フレーム数\n",
    "frame_rate = int(cap.get(cv2.CAP_PROP_FPS)) # フレームレート\n",
    "size = (width, height)\n",
    "fmt = cv2.VideoWriter_fourcc('m', 'p', '4', 'v') # ファイル形式(ここではmp4)\n",
    "writer = cv2.VideoWriter(filepath_output, fmt, frame_rate, size) # ライター作成\n",
    "\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                                #mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,0,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        cv2.namedWindow(\"img\", cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow('img', image)\n",
    "        writer.write(image) \n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ff7d24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#results.face_landmarks.landmark[0].visibility\n",
    "results.face_landmarks.landmark[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db486148",
   "metadata": {},
   "source": [
    "***2. Capture Landmarks & Export to CSV***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06229b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_coords = len(results.pose_landmarks.landmark)+len(results.face_landmarks.landmark)\n",
    "num_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b7e101",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1, num_coords+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1429f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f92c85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coords.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc9eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIVE\n",
    "#cap = cv2.VideoCapture(0)\n",
    "#happy/neutral/peaceful/suiron\n",
    "class_name = \"peaceful\"\n",
    "filepath_input = \"./emotions/peaceful.mp4\"\n",
    "#filepath_output = \"./result/neutral.mp4\"\n",
    "cap = cv2.VideoCapture(filepath_input)\n",
    "\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        # Export coordinates\n",
    "        #CSV出力のためのデータ作成\n",
    "        try:\n",
    "            # Extract Pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            # Extract Face landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "            # Concate rows\n",
    "            row = pose_row+face_row\n",
    "            \n",
    "            # Append class name \n",
    "            row.insert(0, class_name)\n",
    "            \n",
    "            # Export to CSV\n",
    "            with open('coords.csv', mode='a', newline='') as f:\n",
    "                csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(row) \n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        cv2.namedWindow(\"img\", cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow('img', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33f2287",
   "metadata": {},
   "source": [
    "***3. Train Custom Model Using Scikit Learn***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54e7f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSVだと最大列数制限を超えるのでtxtに変換→拡張子変更\n",
    "df = pd.read_csv('coords.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b934c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2096311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f7720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['class']=='happy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102b6a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1) # features\n",
    "y = df['class'] # target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceb88c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443b8fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ecc835",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b503b2",
   "metadata": {},
   "source": [
    "***3.2 Train Machine Learning Classification Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422c46b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3ba139",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1be72f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21ead7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit_models['rc'].predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44032078",
   "metadata": {},
   "source": [
    "***3.3 Evaluate and Serialize Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c61f31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for algo, model in fit_models.items():\n",
    "    yhat = model.predict(X_test)\n",
    "    print(algo, accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf07257",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit_models['rf'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5172ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea1e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "with open('body_language.pkl', 'wb') as f:\n",
    "    pickle.dump(fit_models['rf'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db808f3",
   "metadata": {},
   "source": [
    "***4. Make Detections with Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b442ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "with open('body_language.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a9e0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d606078",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_ = []\n",
    "time_ = []\n",
    "#LIVE\n",
    "#cap = cv2.VideoCapture(0)\n",
    "#happy/neutral/peaceful/suiron\n",
    "start = time.time()\n",
    "filepath_input = \"./emotions/suiron.mp4\"\n",
    "filepath_output = \"./result/suiron.mp4\"\n",
    "cap = cv2.VideoCapture(filepath_input)\n",
    "#video save\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) # 動画の画面横幅\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) # 動画の画面縦幅\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) # 総フレーム数\n",
    "frame_rate = int(cap.get(cv2.CAP_PROP_FPS)) # フレームレート\n",
    "size = (width, height)\n",
    "fmt = cv2.VideoWriter_fourcc('m', 'p', '4', 'v') # ファイル形式(ここではmp4)\n",
    "writer = cv2.VideoWriter(filepath_output, fmt, frame_rate, size) # ライター作成\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        #print(results)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=5, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=5, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=5, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=5, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=5, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=5, circle_radius=2)\n",
    "                                 )\n",
    "        # Export coordinates\n",
    "        #try:\n",
    "        # Extract Pose landmarks\n",
    "        #print(results.pose_landmarks)\n",
    "        #print(results.pose_landmarks.landmark)\n",
    "        if results.pose_landmarks:\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            # Extract Face landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "            # Concate rows\n",
    "            row = pose_row+face_row\n",
    "            \n",
    "#       # Append class name \n",
    "#       row.insert(0, class_name)\n",
    "            \n",
    "#       # Export to CSV\n",
    "#       with open('coords.csv', mode='a', newline='') as f:\n",
    "#             csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#             csv_writer.writerow(row) \n",
    "\n",
    "            # Make Detections\n",
    "            X = pd.DataFrame([row])\n",
    "            body_language_class = model.predict(X)[0]\n",
    "            body_language_prob = model.predict_proba(X)[0]\n",
    "            #print(body_language_class, body_language_prob)\n",
    "            time_diff = time.time() - start\n",
    "            time_.append(time_diff)\n",
    "            prob_.append(body_language_prob)\n",
    "            \n",
    "            # Grab ear coords\n",
    "            coords = tuple(np.multiply(\n",
    "                            np.array(\n",
    "                                (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
    "                                 results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n",
    "                        , [640,480]).astype(int))\n",
    "            \n",
    "            #print(coords)\n",
    "            if body_language_class == 'happy':\n",
    "                cv2.rectangle(image, (50,50), (860, 200), (80, 127, 255), -1)\n",
    "            elif body_language_class == 'neutral':\n",
    "                cv2.rectangle(image, (50,50), (860, 200), (211, 211, 211), -1)\n",
    "            elif body_language_class == 'peaceful':\n",
    "                cv2.rectangle(image, (50,50), (860, 200), (144, 238, 144), -1)\n",
    "            \n",
    "            #cv2.rectangle(image, (coords[0]+1000, coords[1]+1000), (coords[0]+len(body_language_class)*30+1500, coords[1]+150), (245, 117, 16),-1)\n",
    "            \n",
    "            \n",
    "            cv2.putText(image, body_language_class, \n",
    "                        (350,150), cv2.FONT_HERSHEY_TRIPLEX, 3, (255, 255, 255), 3, cv2.LINE_AA)\n",
    "            \n",
    "            # Get status box\n",
    "            \n",
    "            # Display Class\n",
    "            #cv2.putText(image, 'CLASS', (95,12), cv2.FONT_HERSHEY_SIMPLEX, 5, (0, 0, 0), 5, cv2.LINE_AA)\n",
    "            #cv2.putText(image, body_language_class.split(' ')[0], (90,40), cv2.FONT_HERSHEY_SIMPLEX, 5, (255, 255, 255), 5, cv2.LINE_AA)\n",
    "            \n",
    "            # Display Probability\n",
    "            #cv2.putText(image, 'PROB', (15,100), cv2.FONT_HERSHEY_SIMPLEX, 5, (0, 0, 0), 5, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(round(body_language_prob[np.argmax(body_language_prob)],2))\n",
    "                        , (90,150), cv2.FONT_HERSHEY_TRIPLEX, 3, (255, 255, 255), 3, cv2.LINE_AA)\n",
    "            \n",
    "            #except:\n",
    "        else:\n",
    "            pass\n",
    "                        \n",
    "        cv2.namedWindow(\"img\", cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow('img', image)\n",
    "        writer.write(image) \n",
    "        #time.sleep(0.2)\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66b5c9b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prob_ar = np.array(prob_)\n",
    "print(len(prob_ar))\n",
    "print(np.shape(prob_))\n",
    "print(len(time_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c0acea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_prob = pd.DataFrame(prob_ar,columns=['happy', 'neutral', 'peaceful'])\n",
    "df_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2230b6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_ar = np.array(time_)\n",
    "df_time = pd.DataFrame(time_ar,columns=['time'])\n",
    "df_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3043db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sum = pd.concat([df_time, df_prob],axis=1)\n",
    "df_sum_list = df_sum.values.tolist()\n",
    "df_sum_list_ar = np.array(df_sum_list)\n",
    "print(df_sum_list_ar[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232d2712",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('plot_prob.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(df_sum_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc278c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('plot_prob.txt') as f:\n",
    "    reader = csv.reader(f)\n",
    "    prob__ = [row for row in reader]\n",
    "    #for row in reader:\n",
    "        #prob__.append(row)\n",
    "\n",
    "for i in range(len(prob__)):\n",
    "    for j in range(len(prob__[i])):\n",
    "        prob__[i][j] = float(prob__[i][j])\n",
    "\n",
    "prob__ar = np.array(prob__)\n",
    "#int_list = [int(i) for i in sample_list[0]]   \n",
    "print(prob__ar[:,1])\n",
    "print(np.shape(prob__ar))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be703d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step2 グラフフレームの作成\n",
    "fig, ax = plt.subplots(figsize = (18,5),facecolor=\"black\")\n",
    "#fig, ax = plt.subplots(figsize = (18,5),facecolor=\"darkslategray\")\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_color('white')\n",
    "plt.gca().spines['left'].set_color('white')\n",
    "plt.gca().xaxis.label.set_color('red')\n",
    "ax.set_facecolor('black')\n",
    "ax.legend(facecolor=\"black\",edgecolor=\"black\",labelcolor = 'white')\n",
    "\n",
    "for i in range(len(time_)):\n",
    "    # 値を更新\n",
    "    time_diff_ = prob__ar[:,0]\n",
    "    y1 = prob__ar[:,1]\n",
    "    y2 = prob__ar[:,2]\n",
    "    y3 = prob__ar[:,3]\n",
    "\n",
    "    # グラフ描画\n",
    "    #happy/victorius/sad/surprised/等々\n",
    "    #happy\n",
    "    happy_, = ax.plot(time_diff_, y1,label='happy', color='orange', linestyle='-',linewidth=1,alpha=0.8)\n",
    "    #neutral\n",
    "    neutral_, = ax.plot(time_diff_, y2,label='neutral', color='gray', linestyle='-',linewidth=1,alpha=0.8)\n",
    "    #peaceful\n",
    "    peaceful_, = ax.plot(time_diff_, y3,label='peaceful',color='lightgreen', linestyle='-',linewidth=1,alpha=0.8)\n",
    "    \n",
    "    ax.set_xlim(time_diff-10, time_diff+1)\n",
    "    \n",
    "    ax.set_ylim(0,20)\n",
    "    ax.set_xlabel('Time [$sec$]',color='white')\n",
    "    ax.set_ylabel('Proba',color='white')\n",
    "    \n",
    "    ax.tick_params(color='white')\n",
    "    #ax.set_yticks(color='white')\n",
    "    ax.legend(facecolor=\"darkslategray\",edgecolor=\"darkslategray\",labelcolor = 'white',bbox_to_anchor=(1.05, 1))\n",
    "    #plt.grid()\n",
    "    # 0.01秒停止\n",
    "    plt.pause(0.05)\n",
    "    happy_.remove()\n",
    "    neutral_.remove()\n",
    "    peaceful_.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0313dba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
